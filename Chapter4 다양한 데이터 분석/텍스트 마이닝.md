# 대통령 연설문 텍스트 마이닝
문자로 된 데이터에서 가치 있는 정보를 얻어 내는 분석 기법은 **텍스트 마이닝(text mining)**.
텍스트 마이닝을 할 때 가장 먼저 하는 작업은 문장을 구성하는 어절들이 어떤 품사인지 파악하는 형태소 분석(morphology analysis).
명사, 동사, 형용사 등 의미를 지닌 품사를 추출해 어떤 단어가 얼마나 많이 사용됐는지 확인.  
문재인 대통령의 출마 선언문을 이용해 텍스트 마이닝을 하는 방법 알아보기. 대통령 연설문은 문법 오류가 없는 정제된 문장. 전처리 작업이 많이 필요 없어서 텍스트 마이닝에 매우 적합한 자료.

## KoNLPy 패키지 설치
KoNLPy 패키지를 이용하면 한글 텍스트로 형태소 분석 가능.
### 자바 설치
KoNLPy 패키지는 '자바'가 설치되어 있어야 사용 가능.
1. [윈도우 설정 -> 시스템 -> 정보 -> '장치 사양'의 '시스템 종류'] 운영체제 버전 확인.
2. 사용하는 운영 체제 버전에 맞는 설치 파일 다운로드해 설치함.

### KoNLPy 의존성 패키지 설치
어떤 패키지는 다른 패키지의 기능을 이용하기 때문에 다른 패키지를 먼저 설치해야 작동하는데, 패키지가 의존하고 있는 이러한 패키지를 '의존성 패키지'라고 함.
아나콘다 프롬프트에서 KoNLPy의 의존성 패키지인 jpype1을 설치  
```pip install jpype1```  
### KoNLPy 설치
```pip install konlpy```

## 가장 많이 사용된 단어 알아보기
### 연설문 불러오기
대선 출마 선언문이 담겨 있는 speech_moon.txt 파일을 워킹 디렉터리에 삽입. open()으로 파일을 열고 read()를 이용해 불러옴. open()에 입력한 encoding = 'UTF-8'은 불러올 텍스트 파일의 인코딩을 'UTF-8'로 지정하는 기능.
```
moon = open('speech_moon.txt', encoding = 'UTF-8').read()
moon
```
### 불필요한 문자 제거
출력한 결과를 보면 특수 문자, 한자, 공백 등이 포함됨. 이런 요소는 분석 대상이 아니므로 제거해야 함. 문자 처리 패키지인 re의 sub()을 이용해 한글이 아닌 모든 문자를 공백으로 바꾸기.
```
# 불필요한 문자 제거
import re
moon = re.sub('[^가-힣]', ' ', moon)
moon
```
> re.sub()에 입력한 [^가-힣]은 '한글이 아닌 모든 문자'를 의미하는 정규 표현식(regular expression). 정규 표현식은 특정한 규칙을 가진 문자열을 표현하는 언어.
> 이메일 주소, 전화번호처럼 특정한 규칙으로 되어 있는 문자를 찾거나 수정할 때 정규 표현식을 활용.

### 명사 추출
텍스트에서 명사만 추출해 분석할 때가 많음. konlpy.tag.Hannanum()의 nouns()를 이용하면 문장에서 명사 추출 가능.
```
# hannanum 만들기
import konlpy
hannanum = konlpy.tag.Hannanum()

# 명사 추출
hannanum.nouns("대한민국의 영토는 한반도와 그 부속도서로 한다")
```
연설문에서 명사 추출. hannanum.nouns()의 출력 결과는 리스트 자료 구조. 다루기 쉽도록 데이터 프레임으로 변환.
```
# 연설문에서 명사 추출
nouns = hannanum.nouns(moon)
nouns
```
```
# 데이터 프레임으로 변환
import pandas as pd
df_word = pd.DataFrame({'word': nouns})
df_word
```
### 단어 빈도표
한 글자로 된 단어는 의미가 없는 경우가 많으므로 제거. pd.str.len()을 이용해 단어의 글자 수를 나타낸 변수를 추가한 다음 두 글자 이상인 단어만 추출.
```
# 글자 수 추가
df_word['count'] = df_word['word'].str.len()
df_word
```
```
# 두 글자 이상 단어만 남기기
df_word = df_word.query('count >= 2')
df_word.sort_values('count')
```
단어의 사용 빈도를 구하고 빈도순으로 정렬
```
# 단어 빈도 구하기
df_word = df_word.groupby('word', as_index = False)  \    # 단어별 분리
                 .agg(n = ('word', 'count'))  \           # 빈도 구하기
                 .sort_values('n', ascending = False)     # 내림차순 정렬
df_word
```
### 단어 빈도 막대 그래프 만들기
자주 사용된 상위 20개 단어를 추출해 막대 그래프 만들기
```
# 단어 빈도 상위 20개 추출
top20 = df_word.head(20)
top20
```
```
import seaborn as sns
import matplotlib.pyplot as plt

plt.rcParams.update({'font.family'    : 'Malgun Gothic',    # 한글 폰트
                     'figure.dpi'     : '120',              # 해상도
                     'figure.figsize' : [6.5, 6]})          # 가로 세로 크기
# 막대 그래프 만들기
sns.barplot(data = top20, y = 'word', x = 'n')
```
## 워드 클라우드 만들기
워드 클라우드(word cloud)는 단어의 빈도를 구름 모양으로 표현한 그래프. 워드 클라우드를 만들면 단어의 빈도에 따라 글자의 크기와 색깔이 다르게 표현됨. 어떤 단어가 얼마나 많이 사용됐는지 한눈에 파악 가능.
### wordcloud 패키지 설치
```pip install wordcloud```
#### wordcloud 패키지 설치 오류 해결
wordcloud 패키지 설치 과정에서 다음과 같은 에러 메시지가 출력되면 'Microsoft Visual C++'를 먼저 설치
```
error: Microsoft Visual C++ 14.0 or greater is required. Get it with "Microsoft C++ Build Tools"
```
1. 아래 사이트에 접속한 다음 왼쪽 위 [Build Tools 다운로드] 버튼을 클릭해 서맃파일 다운로드
> bit.ly/easypy_103

2. 설치 파일 실행. 설정 화면에서 왼쪽 위 'C++를 사용한 데스크톱 개발'을 체크한 다음 [Install]을 클릭해 설치 시작
3. 아나콘다 프롬프트에서 wordcloud 패키지 설치

### 한글 폰트 설정
워드 클라우드에 한글을 표현하려면 워드 클라우드를 만들 때 한글 폰트를 사용하도록 설정해야 함. 배달의민족 도현체 폰트 파일 DoHyeon-Regular.ttf를 워킹 디레겉리에 삽입한 다음 폰트 경로 지정.
```
font = 'DoHyeon-Regular.ttf'
```
> [윈도우 설정 -> 개인 설정 -> 글꼴]에서 글꼴을 선택하고 '메타데이터'의 '글꼴 파일'을 보면 .ttf 확장자의 폰트 파일 경로를 알 수 있음.

### 단어와 빈도를 담은 딕셔너리 만들기
워드 클라우드는 단어는 키(key), 빈도는 값(value)으로 구성된 딕셔너리 자료 구조를 이용해 만듦. 단어 빈도를 담은 df_word는 데이터 프레임이므로 다음 코드를 이용해 딕셔너리로 변환함.
```
# 데이터 프레임을 딕셔너리로 변환
dic_word = df_word.set_index('word').to_dict()['n']
dic_word
```
### 워드 클라우드 만들기
wordcloud 패키지의 WordCloud()를 이용해 워드 클라우드를 만들 때 사용할 wc를 만듦. WordCloud()의 W와 C는 대문자.
```
# wc 만들기
from wordcloud import WordCloud
wc = WordCloud(random_state = 1234,         # 난수 고정
               font_path = font,            # 폰트 설정
               width = 400,                 # 가로 크기
               height = 400,                # 세로 크기
               background_color = 'white')  # 배경색
```
wc.generate_from_frequencies()를 이용해 워드 클라우드를 만든 다음 plt.imshow()를 이용해 출력함. 워드 클라우드 이미지를 출력하는 코드는 한 셀에 넣어 함께 실행해야 하니 주의.
```
# 워드 클라우드 만들기
img_wordcloud = wc.generate_from_frequencies(dic_word)

# 워드 클라우드 출력하기
plt.figure(figsize = (10, 10))  # 가로, 세로 크기 설정
plt.axis('off')                 # 테두리 선 없애기
plt.imshow(img_wordcloud)       # 워드 클라우드 출력
```
WordCloud()는 함수를 실행할 때마다 난수(무작위로 생성한 수)를 이용해 워드 클라우드를 매번 다른 모양으로 만듦. 워드 클라우드를 항상 같은 모양으로 만들려면 random_state를 이용해 난수를 고정해야 함.
wc를 만드는 코드를 먼저 실행한 다음 wc.generate_from_frequencies()를 실행해야 함. 워드 클라우드는 자주 사용된 단어일수록 글자가 크게, 적게 사용된 단어일 수록 작게 표현됨.
#### 클래스를 이용해 인스턴스 만들기
```
from wordcloud import WordCloud
wc = WordCloud(random_state = 1234,
               font_path = font,
               width = 400,
               height = 400,
               background_color = 'white')
wc.generate_from_frequencies(dic_word)
```
WordCloud()처럼 '메서드와 어트리뷰트를 가지고 있는 변수'를 만드는 명령어를 클래스(class)라고 함. wc처럼 클래스로 만든 변수를 인스턴스(instance)라고 함. 먼저 클래스를 이용해 인스턴스를 만든 다음 사용해야 함. 명사를 추출할 때 사용한 hannanum도 konlpy.tag.Hannanum 클래스로 만든 인스턴스.  
인스턴스를 만들 때 WordCloud(width = 400, height = 400)처럼 파라미터의 값을 미리 지정해 인스턴스를 만들 때 WordCloud(width = 400, height = 400)처럼 파라미터의 값을 미리 지정해두면 메서드를 여러 번 사용하더라도 파라미터를 반복해서 입력하지 않아도 되어 편리. 파라미터를 바꿔가며 여러 인스턴스를 만들어두면 기능이 다른 여러 인스턴스를 동시에 사용할 수 있다는 장점이 있음.
## 워드 클라우드 모양 바꾸기
WordCloud()의 mask를 이용하면 이미지 파일을 이용해 원하는 모양의 워드 클라우드 만들기 가능
### mask 만들기
cloud.png는 구름 모양 그림을 담고 있는 이미지 파일. mask에 사용할 이미지는 테두리가 뚜렷하고 어두운 색일수록 좋음.  
cloud.png를 워킹 디렉터리에 삽입한 다음 PIL 패키지의 Image.open()을 이용해 불러옴.
```
import PIL
icon = PIL.Image.open('cloud.png')
```
```
import numpy as np
img = PIL.Image.new('RGB', icon.size, (255, 255, 255))
img.paste(icon, icon)
img = np.array(img)
```
### 워드 클라우드 만들기
WordCloud()에 mask = img를 입력해 mask를 활용하도록 설정함.
```
# wc 만들기
wc = WordCloud(random_state = 1234,          # 난수 고정
               font_path = font,             # 폰트 설정
               width = 400,                  # 가로 크기
               height = 400,                 # 세로 크기
               background_color = 'white',   # 배경색
               mask = img)                   # mask 설정
```
```
# 워드 클라우드 만들기
img_wordcloud = wc.generate_from_frequencies(dic_word)

# 워드 클라우드 출력하기
plt.figure(figsize = (10, 10))    # 가로, 세로 크기 설정
plt.axis('off')                   # 테두리 선 없애기
plt.imshow(img_wordcloud)         # 워드 클라우드 출력
```
## 워드 클라우드 색깔 바꾸기
컬러맵(colormaps, 색깔 목록)을 이용하면 워드 클라우드의 색깔을 다양하게 바꿀 수 있음. WordCloud()에 colormap = 'inferno'를 입력해 inferno 컬러맵을 적용하도록 설정함.
```
# wc 만들기
wc = WordCloud(random_state = 1234,          # 난수 고정
               font_path = font,             # 폰트 설정
               width = 400,                  # 가로 크기
               height = 400,                 # 세로 크기
               background_color = 'white',   # 배경색
               mask = img,                   # mask 설정
               colormap = 'inferno')         # 컬러맵 설정
```
```
# 워드 클라우드 만들기
img_wordcloud = wc.generate_from_frequencies(dic_word)

# 워드 클라우드 출력하기
plt.figure(figsize = (10, 10))  # 가로, 세로 크기 설정
plt.axis('off')                 # 테두리 선 없애기
plt.imshow(img_wordcloud)       # 워드 클라우드 출력
```
> 다양한 컬러맵 이용하기  
> 그래프를 만들 때 다양한 컬러맵을 이용 가능.  
> Choosing Colormaps in Matplotlib: bit.ly/easypy_104

# 기사 댓글 텍스트 마이닝
## 가장 많이 사용된 단어 알아보기
### 기사 댓글 불러오기
news_comment_BTS.csv 파일을 워킹 디렉터리에 삽입한 다음 불러 오기.
```
# 데이터 불러오기
import pandas as pd
df = pd.read_csv('news_comment_BTS.csv', encoding = 'UTF-8')

# 데이터 살펴보기
df.info()
```
### 불필요한 문자 제거
댓글이 들어 있는 reply 변수에서 불필요한 문자를 제거하고 한글만 남긴 다음 일부를 출력해 내용을 확인. 여기서 분석하는 reply는 데이터 프레임에 담겨 있는 변수이므로 str.replace()를 사용해야 함.
```
# 불필요한 문자 제거
df['reply'] = df['reply'].str.replace('[^가-힣]', ' ', regex = True)
df['reply'].head()
```
### 명사 추출
꼬꼬마(Kkma) 형태소 분석기를 이용해 댓글에서 명사 추출. 꼬꼬마 형태소 분석기는 띄어쓰기 오류가 있는 문장에서도 형태소를 잘 추출하는 장점이 있음. 댓글처럼 정제되지 않은 텍스트를 분석할 때 적합. Kkma()에서 첫 글자 K는 대문자이므로 주의.
```
# kkma 만들기
import konlpy
kkma = konlpy.tag.Kkma()
```
이번에 추출할 reply는 데이터 프레임에 들어 있는 변수이므로 kkma.nouns()에 바로 적용할 수 없고, apply()를 사용해 함수가 각 행의 값을 따로따로 처리하게 해야 함.
```
# 명사 추출 - apply() 활용
nouns = df['reply'].apply(kkma.nouns)
nouns
```
### 단어 빈도표 만들기
단어가 몇 번씩 사용됐는지 나타낸 빈도표 만들기. nouns는 행마다 여러 단어가 리스트 자료 구조로 들어 있음. df.explode()를 이용해 한 행에 한 단어만 들어가도록 함.
```
# 한 행에 한 단어가 들어가도록 구성
nouns = nouns.explode()
nouns
```
nouns로 데이터 프레임을 만든 다음 두 글자 이상으로 된 단어만 남기고 단어 빈도표를 만들기.
```
# 데이터 프레임 만들기
df_word = pd.DataFrame({'word': nouns})

# 글자 수 추가
df_word['count'] = df_word['word'].str.len()

# 두 글자 이상 단어만 남기기
df_word = df_word.query('count >= 2')
df_word
```
```
# 빈도표 만들기
df_word = df_word.groupby('word', as_index = False)  \    # 단어별 분리
                 .agg(n = ('word', 'count'))  \           # 빈도 구하기
                 .sort_values('n', ascending = False)     # 내림차순 정렬
df_word
```
### 단어 빈도 막대 그래프 만들기
댓글에 어떤 단어가 많이 사용됐는지 알아보기 쉽도록 자주 사용된 상위 20개 단어를 추출해 막대 그래프를 만들기.
```
# 단어 빈도 상위 20개 추출
top20 = df_word.head(20)
top20
```
```
# 가로 세로 크기 설정
plt.rcParams.update({'figure.figsize' = [6.5, 6]})

# 막대 그래프 만들기
sns.barplot(data = top20, y = 'word', x = 'n')
```
## 워드 클라우드 만들기
기사 댓글에 사용된 단어를 이용해 워드 클라우드 만들기. 데이터 프레임으로 되어 있는 df_word를 딕셔너리 자료 구조로 변환함.
```
# 데이터 프레임을 딕셔너리로 변환
dic_word = df_word.set_index('word').to_dict()['n']
```
wc()를 만든 다음 wc.generate_from_frequencies()를 이용해 워드 클라우드를 만듦.
```
# wc 만들기
wc = WordCloud(random_state = 1234,         # 난수 고정
               font_path = font,            # 폰트 설정
               width = 400,                 # 가로 크기
               height = 400,                # 세로 크기
               background_color = 'white',  # 배경색
               mask = img)                  # mask 설정
```
```
# 워드 클라우드 만들기
img_wordcloud = wc.generate_from_frequencies(dic_word)

# 워드 클라우드 출력하기
plt.figure(figsize = (10, 10))    # 가로, 세로 크기 설정
plt.axis('off')                   # 테두리 선 없애기
plt.imshow(img_wordcloud)         # 워드 클라우드 출력
```
### 텍스트 마이닝 더 알아보기
다양한 형태소 분석기 이용하기
KoNLPy를 이용하면 한나눔, 꼬꼬마 외에도 다양한 형태소 분석기를 이용 가능. 명사뿐 아니라 동사, 형용사 등 다양한 품사를 추출 가능.
